---
id: fb1749d9-fc4a-466d-abfc-c1f886cbf3f9
title: Matt Ambrogi
tags:
  - RSS
date_published: 2024-09-23 15:04:17
---

# Matt Ambrogi
#Omnivore

[Read on Omnivore](https://omnivore.app/me/matt-ambrogi-192211f412c)
[Read Original](https://www.mattambrogi.com/posts/claude-prefill/)



[mattambrogi](https:&#x2F;&#x2F;www.mattambrogi.com&#x2F;) 

* [Posts](https:&#x2F;&#x2F;www.mattambrogi.com&#x2F;posts&#x2F;)
* [Projects](https:&#x2F;&#x2F;www.mattambrogi.com&#x2F;projects)
* [Notes](https:&#x2F;&#x2F;www.mattambrogi.com&#x2F;notes&#x2F;)
* [Twitter](https:&#x2F;&#x2F;twitter.com&#x2F;matt%5Fambrogi)

## Utilizing Claude&#39;s Prefil Capabilities

I&#39;ve been exploring ways to improve the reliability and consistency of JSON generation using Claude, Anthropic&#39;s large language model. Here are some key observations and insights from my experiments:

**Observations**

• The initial approach without prefill resulted in inconsistent formatting and unwanted text.

• Using Claude&#39;s prefill ability significantly improved the output quality:

 \- No more &quot;Certainly!&quot; or other extraneous text

 \- JSON structure was more consistent

• Adding a stop sequence further refined the output:

 \- Ensured no extra content appeared at the end of the JSON

 \- Resulted in cleaner, more predictable responses

**Key takeaways:**

• Prefill is a powerful tool for guiding Claude&#39;s output format

• Stop sequences can be used to precisely control where the model stops generating

• These techniques together produce much more reliable structured data

**Potential improvements and considerations:**

• Experiment with different prefill prompts to optimize for specific use cases

• Investigate how temperature and other parameters affect output consistency

• Consider implementing error handling for cases where JSON parsing fails

**Broader implications:**

• These techniques could be applied to generate various types of structured data

• May reduce the need for complex post-processing of LLM outputs

• Could enable more robust integration of LLMs into data pipelines and APIs

The ability to reliably generate structured data opens up new possibilities for using LLMs in more technical and data-oriented applications. It&#39;s exciting to see how simple prompting techniques can dramatically improve output quality and consistency.

**Note**

 \- These notes were AI generated by providing [Spiral](https:&#x2F;&#x2F;spiral.computer&#x2F;) with the code from [this repo](https:&#x2F;&#x2F;github.com&#x2F;mattambrogi&#x2F;claude-prefill-and-stop-sequence). Spiral is a product built by the team at [Every](https:&#x2F;&#x2F;every.to&#x2F;), which I&#39;ve found to be very good at tranforming content from one medium to another. The notes are shown as generated by Spiral, without edits outside of light formatting.